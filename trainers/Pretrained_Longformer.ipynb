{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96879747-982f-49b5-ad39-97738cc42334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# mkdirs('./logs')\n",
    "logging.basicConfig(filename=os.path.join('./logs', 'longformer.log'),\n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                    datefmt='%m-%d %H:%M', level=logging.DEBUG, filemode='w')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# training parameters\n",
    "model_config = {}\n",
    "\n",
    "model_config[\"train_size\"] = 500\n",
    "model_config[\"val_size\"] = 100\n",
    "model_config[\"test_size\"] = 100\n",
    "\n",
    "# model_config['lr'] = 1e-4\n",
    "model_config['window_size'] = 64\n",
    "model_config['batch_size'] = 2\n",
    "model_config['max_len'] = 4096\n",
    "model_config[\"datapath\"] = \"./Long-document-dataset\"\n",
    "model_config[\"weight_path\"] = \"./weight\"\n",
    "model_config[\"num_epoch\"] = 5\n",
    "model_config[\"model_weight_path\"] = None\n",
    "model_config[\"longformer_lr\"] = 1e-6\n",
    "model_config[\"linear_lr\"] = 1e-4\n",
    "model_config[\"gamma\"] = 0.8\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "logger.info(model_config)\n",
    "\n",
    "# create custom dataset class for arvix classification dataset\n",
    "class ArvixDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, model_config, mode='train', max_len=4096):\n",
    "\n",
    "        self.dictCls2Idx = {\n",
    "            \"cs.AI\": 0,\n",
    "            \"cs.cv\": 1,\n",
    "            \"cs.IT\": 2,\n",
    "            \"cs.PL\": 3,\n",
    "            \"math.AC\": 4,\n",
    "            \"math.ST\": 5,\n",
    "            \"cs.CE\": 6, \n",
    "            \"cs.DS\": 7,\n",
    "            \"cs.NE\": 8,\n",
    "            \"cs.SY\": 9 , \n",
    "            \"math.GR\": 10\n",
    "        }\n",
    "        self.Idx2dictCls = {}\n",
    "        self.dataset = []\n",
    "        self.labels  = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for sub in self.dictCls2Idx:\n",
    "            label_index = self.dictCls2Idx[sub]\n",
    "            subfolder = os.path.join(path,sub)\n",
    "            self.Idx2dictCls[label_index] = sub\n",
    "\n",
    "            files = sorted([f for f in os.listdir(subfolder) if os.path.isfile(os.path.join(subfolder,f))])\n",
    "            random.seed(1234)\n",
    "            random.shuffle(files)\n",
    "\n",
    "            if mode == \"train\":\n",
    "                file_index = [i for i in range(model_config[\"train_size\"])]\n",
    "            elif mode == \"validation\":\n",
    "                file_index = [i for i in range(model_config[\"train_size\"], model_config[\"train_size\"] + model_config[\"val_size\"])]\n",
    "            elif mode == \"test\":\n",
    "                file_index = [i for i in range(model_config[\"train_size\"] + model_config[\"val_size\"], model_config[\"train_size\"] + model_config[\"val_size\"] + model_config[\"test_size\"])]\n",
    "\n",
    "            for i in file_index:\n",
    "                f = files[i]\n",
    "                fname = os.path.join(subfolder,f)\n",
    "                self.dataset.append(fname)\n",
    "                self.labels.append(label_index)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        data_path = self.dataset[idx]\n",
    "        data = self.read_txt(data_path)\n",
    "        encoded_data = self.tokenizer.encode(data, truncation=True, padding=\"max_length\", max_length=self.max_len)\n",
    "        att_mask = torch.ones(len(encoded_data), dtype=torch.long)\n",
    "        att_mask[0] = 2\n",
    "        sample = {\"Text\": torch.tensor(encoded_data), \n",
    "                  \"Attention\": att_mask, \n",
    "                  \"Label\": torch.Tensor([label])}\n",
    "        return sample\n",
    "\n",
    "    def read_txt(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read().replace('\\n', '')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd37fa20-7d25-4eef-aca7-86b2399516fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from longformer.longformer import Longformer, LongformerConfig\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizerFast\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed61d3da-31f2-4ac7-83e8-4915a90441c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LongformerConfig.from_pretrained('longformer-base-4096/') \n",
    "config.attention_mode = 'sliding_chunks'\n",
    "config.attention_window = [model_config['window_size']] * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751caaf1-1ce6-43c8-8b17-95e30f1e73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongformerClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features=768, out_features=11):\n",
    "        super(LongformerClassifier, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.longformer = Longformer.from_pretrained('longformer-base-4096/', config=config)\n",
    "        self.linear = torch.nn.Linear(in_features=in_features, out_features=out_features)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.longformer(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        x = self.linear(x[:, 0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cc9ca0-fe1d-4df7-b7f1-fe1748310fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', model_max_length=model_config[\"max_len\"])\n",
    "train_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"train\", max_len=model_config[\"max_len\"])\n",
    "val_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"validation\", max_len=model_config[\"max_len\"])\n",
    "test_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"test\", max_len=model_config[\"max_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0fa1b5-5f62-4c27-94d2-aa804fa66b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=model_config['batch_size'], shuffle=True, collate_fn=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=model_config['batch_size'], shuffle=False, collate_fn=None)\n",
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0187b9d-7f89-4a7b-b444-bae940d937bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongformerClassifier().to(device)\n",
    "\n",
    "if model_config[\"model_weight_path\"] is not None:\n",
    "    file_name = os.path.join(model_config[\"weight_path\"], model_config[\"model_weight_path\"])\n",
    "    model = torch.load(file_name).to(device)\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr = model_config[\"lr\"])\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.longformer.parameters(), 'lr': model_config[\"longformer_lr\"]},\n",
    "    {'params': model.linear.parameters(), 'lr': model_config[\"linear_lr\"]}])\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=model_config[\"gamma\"], last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0574ddda-9633-4e12-8cf3-d8bf0f647057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba286baa-cc89-492b-9f01-91e5ddea43eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning rate for longformer: 1e-06, for linear layer: 0.0001\n",
      "Loss after 0 step: 2.3883461952209473\n",
      "Loss after 10 step: 2.5824050903320312\n",
      "Loss after 20 step: 2.7779407501220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19114/3472136321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19114/3821146312.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         )\n\u001b[1;32m    837\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                 )\n\u001b[1;32m    492\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         )\n\u001b[1;32m    414\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         )\n\u001b[1;32m    351\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/longformer/longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mkey_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mextra_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mremove_from_windowed_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(model_config[\"num_epoch\"])):\n",
    "    logger.info(\"in epoch:\" + str(round))\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    current_lr = scheduler.get_last_lr()\n",
    "    print(f\"Current Learning rate for longformer: {current_lr[0]}, for linear layer: {current_lr[1]}\")\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        start=time.time()\n",
    "        input_ids = data[\"Text\"].to(device)\n",
    "        attention_mask = data[\"Attention\"].to(device)\n",
    "        label = data[\"Label\"].to(device)\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = loss_fn(outputs, label.squeeze(1).long())\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        end=time.time()\n",
    "        logger.info(\"Epoch: \" + str(epoch)+ \" Step: \" + str(step)+ \" Loss: \" + str(loss.item()) + \" Time: \" + str(end-start))\n",
    "        \n",
    "        if(step % 10 == 0):\n",
    "            print(f\"Loss after {step} step: {loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)   \n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "\n",
    "    # save model weight\n",
    "    print(\"Saving model weight...\")\n",
    "\n",
    "    if not os.path.exists(model_config['weight_path']):\n",
    "        os.makedirs(model_config['weight_path'])\n",
    "\n",
    "    weight_file_name = f\"{model_config['weight_path']}/e{epoch}_model.pt\"\n",
    "    torch.save(model.state_dict(), weight_file_name)\n",
    "        \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    # Put the model in evaluation mode-\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "    for step, data in enumerate(val_dataloader):\n",
    "        \n",
    "        input_ids = data[\"Text\"].to(device)\n",
    "        attention_mask = data[\"Attention\"].to(device)\n",
    "        label = data[\"Label\"].to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        loss = loss_fn(outputs, label.squeeze(1).long())\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        label_ids = label.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    logger.info(\"Epoch: \" + str(epoch) + \"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    logger.info(\"Epoch: \" + str(epoch) + \"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5ee3f-3097-4454-85ad-2fea365b5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Calculator:\n",
    "    def __init__(self, num_class=11):\n",
    "        self.num_class = num_class\n",
    "        self.dictIdx2Cls = {\n",
    "            0: \"cs.AI\",\n",
    "            1: \"cs.cv\",\n",
    "            2: \"cs.IT\",\n",
    "            3: \"cs.PL\",\n",
    "            4: \"math.AC\",\n",
    "            5: \"math.ST\",\n",
    "            6: \"cs.CE\", \n",
    "            7: \"cs.DS\",\n",
    "            8: \"cs.NE\",\n",
    "            9: \"cs.SY\", \n",
    "            10: \"math.GR\"\n",
    "        }\n",
    "\n",
    "    def init_metrics(self):\n",
    "        class_list = [i for i in range(self.num_class)]\n",
    "        val_list = [0] * self.num_class\n",
    "\n",
    "        self.TP = dict(zip(class_list, val_list))\n",
    "        self.positive_pred = dict(zip(class_list, val_list))\n",
    "        self.positive_label = dict(zip(class_list, val_list))\n",
    "\n",
    "        self.precision = dict(zip(class_list, val_list))\n",
    "        self.recall = dict(zip(class_list, val_list))\n",
    "        self.f1 = dict(zip(class_list, val_list))\n",
    "\n",
    "    def update_result(self, preds, labels):\n",
    "        preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "\n",
    "            this_pred = np.array([1 if pred == i else 0 for pred in preds_flat])\n",
    "            this_label = np.array([1 if label == i else 0 for label in labels_flat])\n",
    "\n",
    "            self.TP[i] += np.sum(this_pred * this_label)\n",
    "            self.positive_pred[i] += np.sum(this_pred)\n",
    "            self.positive_label[i] += np.sum(this_label)\n",
    "\n",
    "    def get_overall_performance(self):\n",
    "\n",
    "        precision = sum(self.TP.values()) / sum(self.positive_pred.values())\n",
    "        recall = sum(self.TP.values()) / sum(self.positive_label.values())\n",
    "        f1 = (2 * sum(np.array(list(result_calculator.precision.values())) * np.array(list(result_calculator.recall.values())))) / (sum(self.precision.values()) + sum(self.recall.values()))\n",
    "        # accuracy = sum(self.correct.values()) / sum(self.total.values())\n",
    "        total = sum(self.positive_label.values())\n",
    "\n",
    "        return [\"overall\", total, precision, recall, f1]\n",
    "\n",
    "    def get_metrics(self):\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "\n",
    "            self.precision[i] = (self.TP[i] / self.positive_pred[i]) if self.positive_pred[i] else 0\n",
    "            self.recall[i] = (self.TP[i] / self.positive_label[i]) if self.positive_label[i] else 0\n",
    "            self.f1[i] = (2.0 * self.precision[i] * self.recall[i] / (self.precision[i] + self.recall[i])) if (self.precision[i] + self.recall[i]) else 0\n",
    "            # self.accuracy[i] = self.correct[i] / self.total[i] if self.total[i] else 0\n",
    "     \n",
    "        result_dict = {\n",
    "            \"Class\": self.dictIdx2Cls.values(),\n",
    "            \"Sample Size\": self.positive_label.values(),\n",
    "            # \"Accuracy\": self.accuracy.values(),\n",
    "            \"Precision\": self.precision.values(),\n",
    "            \"Recall\": self.recall.values(),\n",
    "            \"F1\": self.f1.values()\n",
    "        }\n",
    "\n",
    "        result_df = pd.DataFrame(result_dict)\n",
    "        result_df.loc[len(result_df.index)] = self.get_overall_performance()\n",
    "\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c1b4c-81f1-4360-b128-a15fbde423f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"no_pretrain_weight/e8_model.pt\"))\n",
    "print(f\"Load model weight from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5c1ad-1c32-4f11-9b7b-cf4a08dea5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"test\", max_len=model_config[\"max_len\"])\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=model_config['batch_size'], shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fc5fe-158b-4cd9-906f-cd8f0b305d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_accuracy = 0\n",
    "\n",
    "result_calculator = Calculator(num_class=11)\n",
    "result_calculator.init_metrics()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, data in enumerate(tqdm(test_dataloader)):\n",
    "    start = time.time()\n",
    "    input_ids = data[\"Text\"].to(device)\n",
    "    attention_mask = data[\"Attention\"].to(device)\n",
    "    label = data[\"Label\"].to(device)\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(input_ids, attention_mask = attention_mask)\n",
    "        \n",
    "    # Accumulate the validation loss.\n",
    "    # loss = loss_fn(outputs, label.squeeze(1).long())\n",
    "    # total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = outputs.detach().cpu().numpy()\n",
    "    label_ids = label.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the metrics for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    result_calculator.update_result(logits, label_ids)\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "print(\"\")\n",
    "print(\"Test  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "\n",
    "# Report the final metrics for this test run.\n",
    "result_df = result_calculator.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0bcd6-071f-46b1-adb2-83801947efa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
