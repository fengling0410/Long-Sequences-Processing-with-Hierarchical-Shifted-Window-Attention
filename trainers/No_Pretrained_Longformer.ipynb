{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9660e8-d9a7-47c7-8871-97aec4e58811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# create custom dataset class for arvix classification dataset\n",
    "class ArvixDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, model_config, mode='train', max_len=4096):\n",
    "\n",
    "        self.dictCls2Idx = {\n",
    "            \"cs.AI\": 0,\n",
    "            \"cs.cv\": 1,\n",
    "            \"cs.IT\": 2,\n",
    "            \"cs.PL\": 3,\n",
    "            \"math.AC\": 4,\n",
    "            \"math.ST\": 5,\n",
    "            \"cs.CE\": 6, \n",
    "            \"cs.DS\": 7,\n",
    "            \"cs.NE\": 8,\n",
    "            \"cs.SY\": 9 , \n",
    "            \"math.GR\": 10\n",
    "        }\n",
    "        self.Idx2dictCls = {}\n",
    "        self.dataset = []\n",
    "        self.labels  = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for sub in self.dictCls2Idx:\n",
    "            label_index = self.dictCls2Idx[sub]\n",
    "            subfolder = os.path.join(path,sub)\n",
    "            self.Idx2dictCls[label_index] = sub\n",
    "\n",
    "            files = sorted([f for f in os.listdir(subfolder) if os.path.isfile(os.path.join(subfolder,f))])\n",
    "            random.seed(1234)\n",
    "            random.shuffle(files)\n",
    "\n",
    "            if mode == \"train\":\n",
    "                file_index = [i for i in range(model_config[\"train_size\"])]\n",
    "            elif mode == \"validation\":\n",
    "                file_index = [i for i in range(model_config[\"train_size\"], model_config[\"train_size\"] + model_config[\"val_size\"])]\n",
    "            elif mode == \"test\":\n",
    "                file_index = [i for i in range(model_config[\"train_size\"] + model_config[\"val_size\"], model_config[\"train_size\"] + model_config[\"val_size\"] + model_config[\"test_size\"])]\n",
    "\n",
    "            for i in file_index:\n",
    "                f = files[i]\n",
    "                fname = os.path.join(subfolder,f)\n",
    "                self.dataset.append(fname)\n",
    "                self.labels.append(label_index)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        data_path = self.dataset[idx]\n",
    "        data = self.read_txt(data_path)\n",
    "        encoded_data = self.tokenizer.encode(data, truncation=True, padding=\"max_length\", max_length=self.max_len)\n",
    "        att_mask = torch.ones(len(encoded_data), dtype=torch.long)\n",
    "        att_mask[0] = 2\n",
    "        sample = {\"Text\": torch.tensor(encoded_data), \n",
    "                  \"Attention\": att_mask, \n",
    "                  \"Label\": torch.Tensor([label])}\n",
    "        return sample\n",
    "\n",
    "    def read_txt(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read().replace('\\n', '')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0966b7d0-de10-4514-b4b7-4a9b3a237260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from longformer.longformer import Longformer, LongformerConfig\n",
    "from transformers import LongformerConfig, LongformerModel\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizerFast\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc55e0e2-e9f8-45bd-8652-3a6cdfe8ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=os.path.join('./logs', 'longformer_nopretrained.log'),\n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                    datefmt='%m-%d %H:%M', level=logging.INFO, filemode='w')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe3fcb3-061d-4396-9099-6444d8ca0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "model_config = {}\n",
    "\n",
    "model_config[\"train_size\"] = 2300\n",
    "model_config[\"val_size\"] = 100\n",
    "model_config[\"test_size\"] = 100\n",
    "\n",
    "model_config['lr'] = 1e-6\n",
    "model_config['window_size'] = 64\n",
    "model_config['batch_size'] = 2\n",
    "model_config['max_len'] = 4096\n",
    "model_config[\"datapath\"] = \"./Long-document-dataset/\"\n",
    "model_config[\"weight_path\"] = \"./no_pretrain_weight/\"\n",
    "model_config[\"num_epoch\"] = 20\n",
    "model_config[\"weight_name\"] = \"e4_model.pt\"\n",
    "model_config[\"longformer_lr\"] = 1e-6\n",
    "model_config[\"linear_lr\"] = 1e-6\n",
    "model_config[\"gamma\"] = 0.8\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8881cab0-13fc-4246-944b-607cd9391245",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LongformerConfig.from_pretrained('longformer-base-4096/') \n",
    "config.attention_mode = 'sliding_chunks'\n",
    "config.attention_window = [model_config['window_size']] * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490a37f0-642f-403c-88b1-b84dc87adb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongformerClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config, pretrain=False, in_features=768, out_features=11):\n",
    "        super(LongformerClassifier, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.pretrain = pretrain\n",
    "        self.config = config\n",
    "\n",
    "        if self.pretrain:\n",
    "            self.longformer = Longformer.from_pretrained('longformer-base-4096/', config=self.config)\n",
    "        else:\n",
    "            self.longformer = LongformerModel(self.config)\n",
    "\n",
    "        self.linear = torch.nn.Linear(in_features=self.in_features, out_features=self.out_features)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.longformer(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        x = self.linear(x[:, 0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f26efca-7718-4525-8c28-a63aa32fec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', model_max_length=model_config[\"max_len\"])\n",
    "train_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"train\", max_len=model_config[\"max_len\"])\n",
    "val_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"validation\", max_len=model_config[\"max_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1292b0-2c29-457d-a465-af16706ab6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=model_config['batch_size'], shuffle=True, collate_fn=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=model_config['batch_size'], shuffle=False, collate_fn=None)\n",
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cd97a55-d7e2-44c9-a157-c562d82444b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model weight from file e4_model.pt\n"
     ]
    }
   ],
   "source": [
    "model = LongformerClassifier(config, pretrain=False, in_features=768, out_features=11).to(device)\n",
    "\n",
    "if model_config[\"weight_name\"] is not None:\n",
    "    file_name = os.path.join(model_config[\"weight_path\"], model_config[\"weight_name\"])\n",
    "    model.load_state_dict(torch.load(file_name))\n",
    "    print(f\"Load model weight from file {model_config['weight_name']}\")\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr = model_config[\"lr\"])\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.longformer.parameters(), 'lr': model_config[\"longformer_lr\"]},\n",
    "    {'params': model.linear.parameters(), 'lr': model_config[\"linear_lr\"]}])\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=model_config[\"gamma\"], last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18b7f23-e9c8-4160-ae85-155c64dbae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c36e6-a556-44d8-8f27-cac7dd0bd19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning rate for longformer: 1e-06, for linear layer: 1e-06\n",
      "Loss after 0 step: 0.8813285827636719\n",
      "Loss after 10 step: 0.6113165616989136\n",
      "Loss after 20 step: 1.02433180809021\n",
      "Loss after 30 step: 2.0124762058258057\n",
      "Loss after 40 step: 0.734704315662384\n",
      "Loss after 50 step: 0.4309670925140381\n",
      "Loss after 60 step: 1.262691855430603\n",
      "Loss after 70 step: 0.8471678495407104\n",
      "Loss after 80 step: 1.9378206729888916\n",
      "Loss after 90 step: 0.3210113048553467\n",
      "Loss after 100 step: 2.408802032470703\n",
      "Loss after 110 step: 0.9046907424926758\n",
      "Loss after 120 step: 0.5376856923103333\n",
      "Loss after 130 step: 0.162942573428154\n",
      "Loss after 140 step: 0.8467928767204285\n",
      "Loss after 150 step: 0.24727031588554382\n",
      "Loss after 160 step: 0.7980748414993286\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(model_config[\"num_epoch\"])):\n",
    "    logger.info(\"in epoch:\" + str(round))\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    current_lr = scheduler.get_last_lr()\n",
    "    logger.info(f\"Current Learning rate: {current_lr}\")\n",
    "    print(f\"Current Learning rate for longformer: {current_lr[0]}, for linear layer: {current_lr[1]}\")\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        \n",
    "        start = time.time()\n",
    "        input_ids = data[\"Text\"].to(device)\n",
    "        attention_mask = data[\"Attention\"].to(device)\n",
    "        label = data[\"Label\"].to(device)\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = loss_fn(outputs, label.squeeze(1).long())\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        end = time.time()\n",
    "\n",
    "        if(step % 10 == 0):\n",
    "            logger.info(f\"Loss after {step} step: {loss} Time: {end-start}\")\n",
    "            print(f\"Loss after {step} step: {loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    logger.info(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "\n",
    "    # save model weight\n",
    "    print(\"Saving model weight...\")\n",
    "\n",
    "    if not os.path.exists(model_config['weight_path']):\n",
    "        os.makedirs(model_config['weight_path'])\n",
    "    \n",
    "    weight_file_name = f\"{model_config['weight_path']}/e{epoch+5}_model.pt\"\n",
    "    torch.save(model.state_dict(), weight_file_name)\n",
    "        \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    # Put the model in evaluation mode-\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "    for step, data in enumerate(val_dataloader):\n",
    "        \n",
    "        input_ids = data[\"Text\"].to(device)\n",
    "        attention_mask = data[\"Attention\"].to(device)\n",
    "        label = data[\"Label\"].to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        loss = loss_fn(outputs, label.squeeze(1).long())\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        label_ids = label.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    logger.info(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    logger.info(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0e77c4-7a7c-4af8-bb27-f6babc47a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Calculator:\n",
    "    def __init__(self, num_class=11):\n",
    "        self.num_class = num_class\n",
    "        self.dictIdx2Cls = {\n",
    "            0: \"cs.AI\",\n",
    "            1: \"cs.cv\",\n",
    "            2: \"cs.IT\",\n",
    "            3: \"cs.PL\",\n",
    "            4: \"math.AC\",\n",
    "            5: \"math.ST\",\n",
    "            6: \"cs.CE\", \n",
    "            7: \"cs.DS\",\n",
    "            8: \"cs.NE\",\n",
    "            9: \"cs.SY\", \n",
    "            10: \"math.GR\"\n",
    "        }\n",
    "\n",
    "    def init_metrics(self):\n",
    "        class_list = [i for i in range(self.num_class)]\n",
    "        val_list = [0] * self.num_class\n",
    "\n",
    "        self.TP = dict(zip(class_list, val_list))\n",
    "        self.positive_pred = dict(zip(class_list, val_list))\n",
    "        self.positive_label = dict(zip(class_list, val_list))\n",
    "\n",
    "        self.precision = dict(zip(class_list, val_list))\n",
    "        self.recall = dict(zip(class_list, val_list))\n",
    "        self.f1 = dict(zip(class_list, val_list))\n",
    "\n",
    "    def update_result(self, preds, labels):\n",
    "        preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "\n",
    "            this_pred = np.array([1 if pred == i else 0 for pred in preds_flat])\n",
    "            this_label = np.array([1 if label == i else 0 for label in labels_flat])\n",
    "\n",
    "            self.TP[i] += np.sum(this_pred * this_label)\n",
    "            self.positive_pred[i] += np.sum(this_pred)\n",
    "            self.positive_label[i] += np.sum(this_label)\n",
    "\n",
    "    def get_overall_performance(self):\n",
    "\n",
    "        precision = sum(self.TP.values()) / sum(self.positive_pred.values())\n",
    "        recall = sum(self.TP.values()) / sum(self.positive_label.values())\n",
    "        f1 = (2 * sum(np.array(list(result_calculator.precision.values())) * np.array(list(result_calculator.recall.values())))) / (sum(self.precision.values()) + sum(self.recall.values()))\n",
    "        # accuracy = sum(self.correct.values()) / sum(self.total.values())\n",
    "        total = sum(self.positive_label.values())\n",
    "\n",
    "        return [\"overall\", total, precision, recall, f1]\n",
    "\n",
    "    def get_metrics(self):\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "\n",
    "            self.precision[i] = (self.TP[i] / self.positive_pred[i]) if self.positive_pred[i] else 0\n",
    "            self.recall[i] = (self.TP[i] / self.positive_label[i]) if self.positive_label[i] else 0\n",
    "            self.f1[i] = (2.0 * self.precision[i] * self.recall[i] / (self.precision[i] + self.recall[i])) if (self.precision[i] + self.recall[i]) else 0\n",
    "            # self.accuracy[i] = self.correct[i] / self.total[i] if self.total[i] else 0\n",
    "     \n",
    "        result_dict = {\n",
    "            \"Class\": self.dictIdx2Cls.values(),\n",
    "            \"Sample Size\": self.positive_label.values(),\n",
    "            # \"Accuracy\": self.accuracy.values(),\n",
    "            \"Precision\": self.precision.values(),\n",
    "            \"Recall\": self.recall.values(),\n",
    "            \"F1\": self.f1.values()\n",
    "        }\n",
    "\n",
    "        result_df = pd.DataFrame(result_dict)\n",
    "        result_df.loc[len(result_df.index)] = self.get_overall_performance()\n",
    "\n",
    "        return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b7c27a-c5b6-43ac-8189-bd3cca4d0458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model weight from file\n"
     ]
    }
   ],
   "source": [
    "model = LongformerClassifier(config, pretrain=False, in_features=768, out_features=11).to(device)\n",
    "model.load_state_dict(torch.load(\"no_pretrain_weight/e8_model.pt\"))\n",
    "print(f\"Load model weight from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e7665b-45e2-44f9-ab50-853d436767a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ArvixDataset(model_config[\"datapath\"], tokenizer, model_config, mode=\"test\", max_len=model_config[\"max_len\"])\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=model_config['batch_size'], shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd382c72-dde0-468f-b202-a7950decfc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/550 [00:00<06:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6144452095031738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/550 [00:01<05:39,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5484049320220947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/550 [00:01<05:34,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5475468635559082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/550 [00:02<05:41,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5512967109680176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/550 [00:03<05:35,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5561578273773193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/550 [00:03<05:32,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5475430488586426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/550 [00:04<05:29,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5576865673065186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 8/550 [00:04<05:24,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5498690605163574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/550 [00:05<05:24,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5560493469238281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/550 [00:06<05:26,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5494823455810547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/550 [00:06<05:29,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5531208515167236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/550 [00:07<05:29,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5611796379089355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/550 [00:07<05:29,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553046464920044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/550 [00:08<05:30,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5494897365570068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/550 [00:09<05:28,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5526571273803711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/550 [00:09<05:28,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5634887218475342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/550 [00:10<05:23,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5566298961639404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/550 [00:10<05:19,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5580112934112549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/550 [00:11<05:37,  1.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9527/303688811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Accumulate the validation loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9527/2342309842.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1081\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m                 )\n\u001b[1;32m    774\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mis_index_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mis_index_global_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mis_global_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_index_global_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_test_accuracy = 0\n",
    "\n",
    "result_calculator = Calculator(num_class=11)\n",
    "result_calculator.init_metrics()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, data in enumerate(tqdm(test_dataloader)):\n",
    "    start = time.time()\n",
    "    input_ids = data[\"Text\"].to(device)\n",
    "    attention_mask = data[\"Attention\"].to(device)\n",
    "    label = data[\"Label\"].to(device)\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "    # Accumulate the validation loss.\n",
    "    # loss = loss_fn(outputs, label.squeeze(1).long())\n",
    "    # total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = outputs.detach().cpu().numpy()\n",
    "    label_ids = label.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the metrics for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    result_calculator.update_result(logits, label_ids)\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "print(\"\")\n",
    "print(\"Test  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "\n",
    "# Report the final metrics for this test run.\n",
    "result_df = result_calculator.get_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83a35c05-42d0-43d7-8b9e-3e437de2ef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020890099909166"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62dc0a57-86c0-4339-bbff-645534e3202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result_calculator.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98ea745c-f0d1-44f0-8ac0-eb6581a39234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs.AI</td>\n",
       "      <td>100</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.349515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cs.CE</td>\n",
       "      <td>100</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.506024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cs.DS</td>\n",
       "      <td>100</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.684783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs.IT</td>\n",
       "      <td>100</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.781065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cs.NE</td>\n",
       "      <td>100</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.495575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs.PL</td>\n",
       "      <td>100</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cs.SY</td>\n",
       "      <td>100</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.754902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs.cv</td>\n",
       "      <td>100</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.773585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>math.AC</td>\n",
       "      <td>100</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.875676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>math.GR</td>\n",
       "      <td>100</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>math.ST</td>\n",
       "      <td>100</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overall</td>\n",
       "      <td>1100</td>\n",
       "      <td>0.701818</td>\n",
       "      <td>0.701818</td>\n",
       "      <td>0.742446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  Sample Size  Precision    Recall        F1\n",
       "0     cs.AI          100   0.339623  0.360000  0.349515\n",
       "6     cs.CE          100   0.636364  0.420000  0.506024\n",
       "7     cs.DS          100   0.750000  0.630000  0.684783\n",
       "2     cs.IT          100   0.956522  0.660000  0.781065\n",
       "8     cs.NE          100   0.444444  0.560000  0.495575\n",
       "3     cs.PL          100   0.631579  0.960000  0.761905\n",
       "9     cs.SY          100   0.740385  0.770000  0.754902\n",
       "1     cs.cv          100   0.732143  0.820000  0.773585\n",
       "4   math.AC          100   0.952941  0.810000  0.875676\n",
       "10  math.GR          100   0.863636  0.950000  0.904762\n",
       "5   math.ST          100   0.906977  0.780000  0.838710\n",
       "11  overall         1100   0.701818  0.701818  0.742446"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e1a35d1-5cd7-49df-a54a-001197fc50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nopretrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03729b3d-fddd-41aa-ae21-cead09dcfcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
